
<div align="center">
<img width="800" height="300" alt="image" src="https://github.com/user-attachments/assets/0e0d8de6-2264-40bb-afe7-dd57be017b3f" />

# DeepFake Detector: AI vs Human  
<br>

[Jeferson Acevedo](https://github.com/Jeferson0809) ‚Ä¢ [Samuel Noriega](https://github.com/) ‚Ä¢ [Oscar Silva](https://github.com/)

---

</div>

La creciente sofisticaci√≥n de los modelos generativos ha dificultado la distinci√≥n entre im√°genes reales y aquellas creadas mediante Inteligencia Artificial. Esta problem√°tica afecta la veracidad de la informaci√≥n, la seguridad digital y la confianza en los contenidos visuales que circulan en la web.

Este proyecto desarrolla un **sistema de clasificaci√≥n basado en Deep Learning** capaz de diferenciar im√°genes fotogr√°ficas reales de im√°genes sint√©ticas generadas por IA. Para ello, se realiza un an√°lisis comparativo de diversas arquitecturas de aprendizaje profundo, evaluando su eficiencia y capacidad de generalizaci√≥n ante la heterogeneidad del dataset.

> **Objetivo:** Dise√±ar y evaluar modelos de Deep Learning para la detecci√≥n automatizada de im√°genes generadas por IA.

---

## Enfoques evaluados

1. **Redes Neuronales Profundas (DNN / MLP)**  
   Modelos densos utilizados como l√≠nea base.

2. **CNNs dise√±adas desde cero**  
   Arquitecturas convolucionales ligeras para aprender patrones espaciales.

3. **Transfer Learning con CNNs preentrenadas**  
   Uso de modelos robustos como *ResNet*, *EfficientNet* o *MobileNet*.

4. **Autoencoders para detecci√≥n de anomal√≠as**  
   Se emplea el error de reconstrucci√≥n como indicador de posibles DeepFakes.

---

## Dataset: AI-Generated-vs-Real-Images (Hemg)

üîó **HuggingFace Dataset:** *152,710 im√°genes*  
- 81,174 sint√©ticas  
- 71,536 reales  

Este conjunto destaca por su **alta heterogeneidad visual**: fotograf√≠as reales, arte digitalizado, documentos escaneados, ilustraciones y paisajes.  
En particular, el subconjunto real incluye im√°genes con deterioro f√≠sico (rasgaduras, quemaduras, decoloraci√≥n, ruido anal√≥gico), lo que obliga a los modelos a aprender representaciones robustas que diferencien entre:

- **Ruido natural f√≠sico**, y  
- **Artefactos sint√©ticos** propios de algoritmos generativos.

---

## M√©tricas de evaluaci√≥n

El desempe√±o de los modelos se mide mediante:

- Accuracy  
- Precision  
- Recall  
- F1-Score  

Estas m√©tricas permiten evaluar el nivel de discriminaci√≥n entre im√°genes reales y generadas por IA.

---

## Estructura del repositorio

- `data/` ‚Äî Scripts y notebooks para carga y preparaci√≥n de datos.  
- `images/` ‚Äî Resultados, visualizaciones y ejemplos del modelo.  
- `models/` ‚Äî Implementaci√≥n de arquitecturas evaluadas.  
- `notebooks/` ‚Äî Experimentos y an√°lisis exploratorios.  
- `train/` ‚Äî Scripts de entrenamiento, callbacks y configuraci√≥n de experimentos.  

---

## Ejemplo del dataset

<div align="center">
  
<img src="https://github.com/user-attachments/assets/7b582700-a545-4db7-b16a-cb6223ef5faa" width="55%">

</div>

---

